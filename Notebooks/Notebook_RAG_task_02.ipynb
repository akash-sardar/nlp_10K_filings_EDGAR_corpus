{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3e1a7e",
   "metadata": {},
   "source": [
    "# TASK_02\n",
    "#### Coding Assignment Task # 2\n",
    "- Dataset: IEDGAR SEC filings (public data) -\n",
    "- https://huggingface.co/datasets/eloukas/edgar-corpus\n",
    "- Language: Python\n",
    "- Implementation: Pyspark\n",
    "- Submission: Github repository containing code + plots (jpeg).\n",
    "- Expected Maximum Duration: 3 hours\n",
    "\n",
    "Given a set of documents: create a solution that allows the end user to understand the documents in a two dimensional space and to identify outliers.\n",
    "Task #2 – Gen AI\n",
    "\n",
    "Dataset\n",
    "\n",
    "( Year: 2018-2020\n",
    "\n",
    "( Filing type: 10K\n",
    "\n",
    "( Sections: All\n",
    "\n",
    "( Company: Choose 1.\n",
    "\n",
    "( Choose 5 data attributes to extract from a single year.\n",
    "\n",
    "Steps\n",
    "\n",
    "( Convert documents to chunks\n",
    "\n",
    "( Covert chunks to embeddings\n",
    "\n",
    "( Create a query\n",
    "\n",
    "( Create a prompt to extract data from chunks from a specific year.\n",
    "\n",
    "( Create a validation dataset (5 true values from chunks).\n",
    "\n",
    "( Demonstrate that your LLM can retrieve the correct chunks from your\n",
    "\n",
    "embedding object for the correct year\n",
    "\n",
    "#### Dataset card:\n",
    "This dataset card is based on the paper EDGAR-CORPUS: Billions of Tokens Make The World Go Round authored by Lefteris Loukas et.al, as published in the ECONLP 2021 workshop.\n",
    "This dataset contains the annual reports of public companies from 1993-2020 from SEC EDGAR filings.\n",
    "There is supported functionality to load a specific year.\n",
    "Care: since this is a corpus dataset, different train/val/test splits do not have any special meaning. It's the default HF card format to have train/val/test splits.\n",
    "If you wish to load specific year(s) of specific companies, you probably want to use the open-source software which generated this dataset, EDGAR-CRAWLER: https://github.com/nlpaueb/edgar-crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed12efd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\envs\\coding_task_venv\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "D:\\Softwares\\Anaconda3\\envs\\coding_task_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 44em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import os\n",
    "import regex as re\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import colorcet as cc\n",
    "from scipy.spatial.distance import cdist\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler as sklearnScaler\n",
    "from sklearn.decomposition  import PCA as sklearnPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import size, col, count, when, length, concat_ws, \\\n",
    "                udf, explode, pandas_udf, lit, count, avg, max as spark_max, min as spark_min, length, expr\n",
    "from pyspark.sql.types import ArrayType, StringType, FloatType,  StructType, StructField, DoubleType\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "from pyspark.ml.feature import StandardScaler, PCA\n",
    "\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import bert_score\n",
    "\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_token = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import spacy\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7bc383-7d9e-4f06-a54c-1e1fb426b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "os.environ['JAVA_HOME'] = r'D:\\Softwares\\Microsoft\\jdk-17.0.15.6-hotspot'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cc043c-a172-4d9b-a832-280953e50e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\envs\\coding_task_venv\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd9c778-d2c6-4bc6-8e88-c18c793e0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AIG_SEC_Filing_Analysis\") \\\n",
    "    .master(\"local[8]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.python.worker.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.pyspark.udf.faulthandler.enabled\", \"true\") \\\n",
    "    .config(\"spark.python.worker.faulthandler.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2315f47-ab1a-49b7-8d72-92de8d941087",
   "metadata": {},
   "source": [
    "### Based on the observations:\n",
    "- The text will retain context if split with \"\\n\"\n",
    "- It might also help to consider \":\" as that sometime is identifying the start of a sub-section [ Text between \"\\n\" and \":\" will be the header]\n",
    "- \";\" might signal the end of a contextually similar section\n",
    "- Size of each chunk should be less than 512 tokens or about 2000 characters (to begin with) as I am planning to use BERT based sentence transformers\n",
    "- An overlap startegy of 200 characters to preserve context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c40f7ff-55d0-4a04-a832-700562fe2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_chunks(text:str, overlap: int = 200, chunk_size = 2000)-> list:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = re.sub(r'[\\x00-\\x09\\x0B-\\x1F\\x7F-\\x9F]','', text)\n",
    "    chunks = []\n",
    "\n",
    "    \n",
    "    if len(text) <= chunk_size:\n",
    "        return [text.strip()] if text.strip() else []\n",
    "        \n",
    "    prev_chunk_len = 0  \n",
    "    \n",
    "    while len(text) > chunk_size:\n",
    "        right = chunk_size\n",
    "        \n",
    "        last_newline_index = text[:chunk_size].rfind(\"\\n\")\n",
    "        \n",
    "        if last_newline_index > 0:\n",
    "            right = last_newline_index\n",
    "\n",
    "        # to ensure chunks have complete words instead of cut words\n",
    "        # if right > 0 and text[right-1].isalnum() and text[right].isalnum():\n",
    "        #     last_space = text[:right].rfind(' ')\n",
    "        #     if last_space > right-50 and last_space > 0:\n",
    "        #         right = last_space\n",
    "            \n",
    "        chunk = text[:right].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        if len(chunks) > 1 and prev_chunk_len < 1000 and len(chunks[-1]) < 1000 :\n",
    "            chunks[-2]+=\" \" + chunks[-1]\n",
    "            chunks = chunks[:-1]\n",
    "        \n",
    "        prev_chunk_len = len(chunks[-1])\n",
    "        \n",
    "        if right > overlap:\n",
    "            start = right - overlap\n",
    "            # Prevent index error\n",
    "            while start < len(text):\n",
    "                if start == 0:\n",
    "                    break\n",
    "                if not (text[start].isalnum() and text[start-1].isalnum()):\n",
    "                    break\n",
    "                start += 1\n",
    "            text = text[start:]\n",
    "        else:\n",
    "            text = text[right:]\n",
    "            \n",
    "    if text:\n",
    "        rem = text.strip()\n",
    "        if rem:\n",
    "            chunks.append(rem)        \n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8710c4-0c60-471c-a566-2c716eb69a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = [\n",
    "    \"D:\\\\PracticeProjects\\\\nlp_10K_filings_EDGAR_corpus\\\\Data\\\\data_2018.parquet\",\n",
    "    \"D:\\\\PracticeProjects\\\\nlp_10K_filings_EDGAR_corpus\\\\Data\\\\data_2019.parquet\",\n",
    "    \"D:\\\\PracticeProjects\\\\nlp_10K_filings_EDGAR_corpus\\\\Data\\\\data_2020.parquet\"\n",
    "]\n",
    "\n",
    "df = spark.read.parquet(*file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcb2291-14cd-45be-906b-56b1844dc8ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- filename: string (nullable = true)\n",
      " |-- cik: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- section_1: string (nullable = true)\n",
      " |-- section_1A: string (nullable = true)\n",
      " |-- section_1B: string (nullable = true)\n",
      " |-- section_2: string (nullable = true)\n",
      " |-- section_3: string (nullable = true)\n",
      " |-- section_4: string (nullable = true)\n",
      " |-- section_5: string (nullable = true)\n",
      " |-- section_6: string (nullable = true)\n",
      " |-- section_7: string (nullable = true)\n",
      " |-- section_7A: string (nullable = true)\n",
      " |-- section_8: string (nullable = true)\n",
      " |-- section_9: string (nullable = true)\n",
      " |-- section_9A: string (nullable = true)\n",
      " |-- section_9B: string (nullable = true)\n",
      " |-- section_10: string (nullable = true)\n",
      " |-- section_11: string (nullable = true)\n",
      " |-- section_12: string (nullable = true)\n",
      " |-- section_13: string (nullable = true)\n",
      " |-- section_14: string (nullable = true)\n",
      " |-- section_15: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b81829-9b86-48e7-bed8-0f45be8afb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f039689-9205-4e34-985e-89824ec14ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking_udf = udf(create_custom_chunks, ArrayType(StringType()))       \n",
    "@pandas_udf(returnType = ArrayType(StringType()))\n",
    "def chunk_pandas_udf(series):\n",
    "    return series.apply(create_custom_chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1b75d8-e96f-44c7-979f-e062261b8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns except metadata columns\n",
    "columns = [column for column in df.columns if column not in [\"filename\", \"cik\", \"year\"]]\n",
    "\n",
    "# Create chunks for each section column\n",
    "for column in columns:\n",
    "    df = df.withColumn(f\"{column}_chunked\", chunk_pandas_udf(col(column)))\n",
    "\n",
    "# Explode and collect all sections into unified format\n",
    "all_chunks = []\n",
    "for section_name in columns:\n",
    "    df_section = df.select(\n",
    "        \"cik\", \n",
    "        \"filename\",\n",
    "        \"year\",\n",
    "        explode(col(f\"{section_name}_chunked\")).alias(\"chunk\")\n",
    "    ).filter(length(col(\"chunk\")) > 15) \\\n",
    "    .withColumn(\"section_name\", lit(section_name)) \\\n",
    "    .withColumn(\"chunk_id\", expr(\"uuid()\"))\n",
    "    df_section = df_section.select(\"cik\", \"filename\", \"year\", \"chunk\", \"section_name\",\"chunk_id\")\n",
    "    \n",
    "    all_chunks.append(df_section)\n",
    "\n",
    "# Union all sections into single DataFrame\n",
    "df_exploded = reduce(DataFrame.unionByName, all_chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f078aa3a-bbcb-47be-81d1-75701d3dfd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cik', 'filename', 'year', 'chunk', 'section_name', 'chunk_id']\n"
     ]
    }
   ],
   "source": [
    "print(df_exploded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771e67be-9d7e-4f9a-b98c-5b8ced707b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_pd = df_exploded.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cfd6933-5470-473a-9506-75baf88bc5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:15<00:00, 15.13s/it]\n"
     ]
    }
   ],
   "source": [
    "texts = df_exploded_pd[\"chunk\"].tolist()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts, batch_size=64, show_progress_bar=True, convert_to_numpy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2de5dd4-2605-4c21-89e5-0a27eebc0c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains NaNs? False\n",
      "Number of empty embeddings: 0\n"
     ]
    }
   ],
   "source": [
    "has_nan = np.isnan(embeddings).any()\n",
    "print(f\"Contains NaNs? {has_nan}\")\n",
    "\n",
    "# Check if any embedding vectors are empty or zero vectors\n",
    "empty_vectors = np.sum(embeddings, axis=1) == 0\n",
    "print(f\"Number of empty embeddings: {np.sum(empty_vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb6570e0-a91b-4c6a-b9c9-724d64da1481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed6c706-e6c9-44ee-bc5b-b49054ee3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_pd[\"embeddings\"] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a779467-07e3-481f-b942-8e46fbe8e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = spark.createDataFrame(df_exploded_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2f90cf1-3688-4ad7-aa11-a28b41871412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cik: string (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- chunk: string (nullable = true)\n",
      " |-- section_name: string (nullable = true)\n",
      " |-- chunk_id: string (nullable = true)\n",
      " |-- embeddings: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "203cf29a-8623-4b62-8f85-4f6ae44acc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "753370d5-f639-4d68-ad7b-24cdedb17498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2020|\n",
      "|2018|\n",
      "|2019|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_embedding.select([\"year\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27fe393e-fe28-4a44-9f00-8aca370c7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(text):\n",
    "   \"\"\"\n",
    "   Extract year information from user queries using advanced NLP techniques.\n",
    "\n",
    "   Args:\n",
    "       text (str): Input text from which to extract year information\n",
    "   \n",
    "   Returns:\n",
    "       str or None: Extracted year as string (e.g., \"2019\") or None if no year found\n",
    "   \"\"\"\n",
    "   if not isinstance(text, str):\n",
    "       return None\n",
    "   \n",
    "\n",
    "   entities = NER(text).ents\n",
    "   dates = [ent.text for ent in entities if ent.label_ == \"DATE\"]\n",
    "   pattern = r'(20\\d{2}|19\\d{2})'  # Pattern for years 1900-2099\n",
    "   \n",
    "   # Process NER-identified date entities first\n",
    "   if dates:\n",
    "       for date_text in dates:\n",
    "           match = re.findall(pattern, date_text)\n",
    "           if match:\n",
    "               year = match[0]\n",
    "               print(f\"Extracted year from NER date entity: {year}\")\n",
    "               return year\n",
    "   \n",
    "   # direct text pattern matching\n",
    "   match = re.findall(pattern, text)\n",
    "   if match:\n",
    "       # Handle multiple years by selecting the most recent\n",
    "       years = [int(year) for year in match]\n",
    "       year = str(max(years))  # Prioritize most recent year\n",
    "       print(f\"Extracted year from direct text search: {year}\")\n",
    "       return year\n",
    "   \n",
    "   return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99107e1a-f05b-4700-9c30-ca5093b0279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_using_sbert(texts: list) -> np.array:\n",
    "    try:\n",
    "        # Input validation - check for None, empty, or non-string values\n",
    "        for i, text in enumerate(texts):\n",
    "            if text is None:\n",
    "                raise ValueError(f\"Text at index {i} is None\")\n",
    "            if not isinstance(text, str):\n",
    "                raise ValueError(f\"Text at index {i} is not a string: {type(text)}\")\n",
    "            if not text.strip():\n",
    "                raise ValueError(f\"Text at index {i} is empty or whitespace only\")\n",
    "        \n",
    "        # Use GPU if available, otherwise CPU\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Device: {device}\")\n",
    "    \n",
    "        # Load sentence transformer model\n",
    "        model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "        # Generate embeddings in batches\n",
    "        embeddings = model.encode(texts, \n",
    "                                batch_size=32,         \n",
    "                                show_progress_bar=True,  \n",
    "                                convert_to_numpy=True)\n",
    "        \n",
    "        # Ensure output length matches input length\n",
    "        if len(embeddings) != len(texts):\n",
    "            raise ValueError(f\"Length mismatch: input={len(texts)}, output={len(embeddings)}\")\n",
    "        \n",
    "        if np.isnan(embeddings).any():\n",
    "            raise ValueError(\"Embeddings contain NaN values\")\n",
    "        \n",
    "        empty_vectors = np.sum(embeddings, axis=1) == 0\n",
    "        if np.sum(empty_vectors) > 0:\n",
    "            raise ValueError(\"Embeddings contain empty vectors\")\n",
    "        \n",
    "        return embeddings\n",
    "                \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2deae5d5-e0e5-4809-8e17-bdd62c9c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_k_context(query:str, query_embedding: np.array, df_embedding: DataFrame, k = 3)-> list:\n",
    "   \"\"\"\n",
    "   Retrieve the top-k most relevant document chunks for a given query.\n",
    "  \n",
    "   Args:\n",
    "       query (str): The user's natural language query\n",
    "       query_embedding (np.array): Numerical representation of the query\n",
    "       df_embedding (DataFrame): PySpark DataFrame containing document embeddings\n",
    "       k (int, optional): Number of top chunks to retrieve. Defaults to 3.\n",
    "   \n",
    "   Returns:\n",
    "       list: List of Row objects containing the top-k most relevant chunks with metadata\n",
    "             including company CIK, year, section name, chunk content, chunk ID, and similarity score\n",
    "   \"\"\"\n",
    "   # Extract YEAR from query using NER\n",
    "   year = extract_year(query)\n",
    "   if year:\n",
    "       filtered_embeddings_df = df_embedding.filter(col(\"year\") == year)\n",
    "   else:\n",
    "       filtered_embeddings_df = df_embedding\n",
    "\n",
    "   # Convert query embedding to Spark ML Vector format for computation\n",
    "   query_vector = Vectors.dense(query_embedding)\n",
    "\n",
    "   # Define cosine  using Spark UDF\n",
    "   @udf(DoubleType())\n",
    "   def cosine_similarity(vec):\n",
    "       \"\"\"\n",
    "       Compute cosine similarity between document and query vectors.\n",
    "       \"\"\"\n",
    "       if isinstance(vec, list):\n",
    "           vec = Vectors.dense(vec)\n",
    "       dot = float(vec.dot(query_vector))\n",
    "       norm1 = float(vec.norm(2))\n",
    "       norm2 = float(query_vector.norm(2))\n",
    "       return dot / (norm1 * norm2) if norm1!=0 and norm2 !=0 else 0.0\n",
    "   \n",
    "   # Apply similarity computation and rank results\n",
    "   df_result = filtered_embeddings_df.withColumn(\"score\", cosine_similarity(col(\"embeddings\")))\n",
    "   # Retrieve top-k chunks with comprehensive metadata\n",
    "   top_k_chunks = df_result.orderBy(col(\"score\").desc()).select(\"cik\",\"year\", \"section_name\",\"chunk\",\"chunk_id\", \"score\").take(k)\n",
    "\n",
    "   return top_k_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d29855a-0d14-44eb-ad72-38be02956857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question: str, context: str, query_type: str = \"general\") -> str:\n",
    "   \"\"\"\n",
    "   This method creates tailored prompts that guide the LLM to provide appropriate responses\n",
    "   based on the type of financial query (financial, risk, operational, regulatory, or general).\n",
    "   \n",
    "   Args:\n",
    "       question (str): The user's question about the SEC filing\n",
    "       context (str): Relevant document context retrieved from the knowledge base\n",
    "       query_type (str, optional): Classification of the query type.\n",
    "   \n",
    "   Returns:\n",
    "       str: A formatted prompt string optimized for the specific query type\n",
    "   \"\"\"\n",
    "   \n",
    "   # Base instructions\n",
    "   base_instruction = \"\"\"\n",
    "You are an expert financial analyst reviewing SEC 10-K filings. \n",
    "Analyze the provided context to answer the specific question below.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Base your answer ONLY on the information provided in the context\n",
    "- If the answer is not found in the context, respond with \"not found\"\n",
    "- Be precise and cite specific sections when possible\n",
    "- For questions on numerical values and amounts, respond with just the exact amounts with units (millions, billions, etc.)\n",
    "- If multiple relevant pieces of information exist, provide all of them\n",
    "- The context does not provide information on any question reply with just 'not found'\n",
    "\"\"\"\n",
    "\n",
    "   # Specialized instructions for different query categories\n",
    "   query_instructions = {\n",
    "\n",
    "       \"financial\": \"\"\"\n",
    "- Focus on financial metrics, dollar amounts, and quantitative data\n",
    "- Include timeframes and comparison periods where mentioned\n",
    "- Note any significant changes or trends\n",
    "- For questions on numerical values and amounts, respond with just the exact amounts with units (millions, billions, etc.). Nothing else is needed.\n",
    "\"\"\",\n",
    "       \"risk\": \"\"\"\n",
    "- Identify specific risk factors and their potential impacts\n",
    "- Distinguish between current risks and future uncertainties\n",
    "- Note any risk mitigation strategies mentioned\n",
    "- For questions on numerical values and amounts, respond with just the exact amounts with units (millions, billions, etc.). Nothing else is needed.\n",
    "\"\"\",\n",
    "       \"operational\": \"\"\"\n",
    "- Focus on business operations, processes, and organizational changes\n",
    "- Include geographic locations and business segments\n",
    "- Note any operational improvements or challenges\n",
    "- For questions on numerical values and amounts, respond with just the exact amounts with units (millions, billions, etc.). Nothing else is needed.\n",
    "\"\"\",\n",
    "       \"regulatory\": \"\"\"\n",
    "- Identify regulatory requirements and compliance matters\n",
    "- Note any legal proceedings or regulatory changes\n",
    "- Include relevant dates and jurisdictions\n",
    "- For questions on numerical values and amounts, respond with just the exact amounts with units (millions, billions, etc.). Nothing else is needed.\n",
    "\"\"\",\n",
    "       \"general\": \"\"\"\n",
    "- Provide comprehensive information relevant to the question\n",
    "- Include supporting details and context\n",
    "- Note any qualifications or limitations mentioned\n",
    "- For questions on numerical values and amounts, respond with just the exact amounts with units (millions, billions, etc.). Nothing else is needed.\n",
    "\"\"\"\n",
    "   }\n",
    "   \n",
    "   # Final prompt\n",
    "   context_instruction = f\"\"\"\n",
    "CONTEXT FROM SEC 10-K FILING:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "ANALYSIS or ANSWER:\"\"\"\n",
    "   \n",
    "   # Combine all components into a complete prompt\n",
    "   full_prompt = base_instruction + query_instructions.get(query_type, query_instructions[\"general\"]) + context_instruction\n",
    "   \n",
    "   return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3bb0336-7ac4-49b6-9dc5-0b512440e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list  = [\n",
    "    {\n",
    "        \"query\": \"What is the outstanding amount of Subordinated Debentures in 2020?\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How much money was allocated under the HHSB Act in 2020 ?\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the FDIC's standard maximum deposit insurance amount in 2020 ?\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What amount of wholesale deposit was purchased in 2018 ?\",\n",
    "     },\n",
    "    {\n",
    "        \"query\": \"In the year 2020, what were the general risk that the company was subjected to ?\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How much money was allocated under the CARES Act in 2018 ?\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"As of the year 2019, describe the elements of an extensive regulatory framework which are applicable to bank holding companies and banks ?\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c91b135-a567-482b-99ed-3cd6711c07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [query[\"query\"] for query in query_list if query[\"query\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8081e36e-dd62-427e-aa1c-0d458568cfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the outstanding amount of Subordinated Debentures in 2020?',\n",
       " 'How much money was allocated under the HHSB Act in 2020 ?',\n",
       " \"What is the FDIC's standard maximum deposit insurance amount in 2020 ?\",\n",
       " 'What amount of wholesale deposit was purchased in 2018 ?',\n",
       " 'In the year 2020, what were the general risk that the company was subjected to ?',\n",
       " 'How much money was allocated under the CARES Act in 2018 ?',\n",
       " 'As of the year 2019, describe the elements of an extensive regulatory framework which are applicable to bank holding companies and banks ?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4401273c-95b9-4bc1-9cf3-8cd8e0dfe6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.97it/s]\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = encode_using_sbert(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26551902-1696-4b58-ada3-359061227d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f4b4484-a17d-4909-91f3-2f2be8a06082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted year from NER date entity: 2020\n",
      "Extracted year from NER date entity: 2020\n",
      "Extracted year from NER date entity: 2020\n",
      "Extracted year from NER date entity: 2018\n",
      "Extracted year from NER date entity: 2020\n",
      "Extracted year from NER date entity: 2018\n",
      "Extracted year from NER date entity: 2019\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "for index, query in enumerate(query_list):\n",
    "   # Retrieve top-k relevant chunks for current query\n",
    "   context.append(return_top_k_context(\n",
    "       query[\"query\"],\n",
    "       query_embeddings[index],\n",
    "       df_embedding)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5fa6fff-946c-4719-a8b3-c1dda96ec0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "722fbc08-364b-4225-b74b-4f27bb6d0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, query in enumerate(query_list):\n",
    "   query[\"context\"] = context[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c24802d6-a4f7-4a42-a4dd-fa09eb3c1ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the outstanding amount of Subordinated Debentures in 2020?',\n",
       " 'context': [Row(cik='718413', year='2020', section_name='section_1A', chunk='assets and a reduction in our income. At the same time, the marketability of the property securing a loan may be adversely affected by any reduced demand resulting from higher interest rates.\\nIn addition, increases in interest rates will increase the dividend rate on our Series A preferred stock, which is tied to the prime rate, and the interest rate on our debentures, which is tied to LIBOR. Furthermore, as discussed below, there is uncertainty as to our future interest costs on our subordinated debentures due to the scheduled phase out of LIBOR at the end of 2021. Higher preferred stock dividend payments and debenture interest costs would decrease the amount of funds available for payment of dividends on our common stock.\\nOur interest costs may increase as a result of the retirement of London Interbank Offered Rate (“LIBOR”) as a reference rate for interest payments on our subordinated debentures.', chunk_id='972a00bc-b917-45af-8690-ee685107f9e9', score=0.46296821001663685),\n",
       "  Row(cik='718413', year='2020', section_name='section_1A', chunk='. The federal Financial Stability Oversight Committee has stated that the end or waning use of LIBOR has the potential to significantly disrupt trading in many important types of financial contracts.\\nAs of December 31, 2020, the Company had outstanding $12,887,000 in principal amount of Junior Subordinated Debentures due December 15, 2037, which bear a quarterly floating rate of interest equal to the 3-month LIBOR, plus 2.85%. Under the terms of the Indenture, if 3-month LIBOR is not available, the Trustee may obtain substitute quotations from four leading banks in the London interbank market for their offered rate to prime banks in the London market for U.S. dollar deposits having a three month maturity; if at least two such quotations are provided, the quarterly rate on the Debentures will be the arithmetic mean of such quotations. If fewer than two such quotations are received, the Trustee will request substitute quotations from four major New York City banks for their offered rate to leading European banks for loans in U.S. dollars; if at least two such quotations are provided, the quarterly rate on the Debentures will be the arithmetic mean of such quotations. The Debenture Trustee has not yet informed the Company as to how it intends to proceed. Phase out of LIBOR, including the Debenture Trustee’s implementation of the foregoing provisions, could significantly impact the Company’s interest costs on its Debentures and it is not possible to predict the magnitude of any such increase.\\nOPERATIONAL RISKS\\nAs a participating lender in the SBA’s Paycheck Protection Program (“PPP”), the Company is subject to additional risks that the SBA may not fund some or all PPP loan guaranties and risks of litigation from our customers or other parties regarding the processing of PPP loans.', chunk_id='6a89ecda-bb77-469f-91ec-132a43ca7081', score=0.4409710504407946),\n",
       "  Row(cik='718413', year='2020', section_name='section_1', chunk='for both new first time PPP loans under the existing PPP and the expansion of existing PPP loans for certain qualified, existing PPP borrowers. The Bank has participated in both rounds of PPP lending.\\nTroubled Debt Restructurings and Loan Modifications for Affected Borrowers. The CARES Act, as extended by the CAA, permits banks to suspend requirements under GAAP for loan modifications to borrowers affected by COVID-19 that may otherwise be required to be characterized as TDRs and to suspend any related determination if (i) the borrower was not more than 30 days past due as of December 31, 2019, (ii) the modifications are related to COVID-19, and (iii) the modification occurs between March 1, 2020 and the earlier of 60 days after the date of termination of the national emergency or January 1, 2022. During 2020, the federal bank regulatory authorities also issued guidance to encourage banks to make loan modifications for borrowers affected by COVID-19. The Bank has followed this guidance in providing relief to borrowers affected by the COVID-19 pandemic.\\nEffect on Regulatory Capital. On September 29, 2020, the federal bank regulatory agencies issued a final rule that neutralizes the regulatory capital and liquidity coverage ratio effects of participating in certain COVID-19 liquidity facilities due to the fact there is no credit or market risk associated with exposures pledged to such facilities. As a result, the final rule supports the flow of credit to households and businesses affected by COVID-19.', chunk_id='b8c9e312-7209-4f97-80b8-083c7d481879', score=0.37332880332018836)]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7a20ffe-f824-46c0-b65f-96aa018694d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1a4c23b-43e6-48ae-8e18-201c3dafe986",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ac8484e-5565-4509-b6c9-18ac583c407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in query_list:\n",
    "   # Combine retrieved chunks into a single context string\n",
    "   context = \"\\n\\n\".join([row[\"chunk\"] for row in query[\"context\"]])\n",
    "   question = query[\"query\"]\n",
    "\n",
    "   # Query Type Classification\n",
    "   query_type_prompt = f\"\"\"\n",
    "   This is a question on SEC 10-K filing of a company: {question}. \n",
    "   As an expert on SEC 10-K forms categorize the question into one of the below categories:\n",
    "   financial, risk, operation, regulatory and general. No Other categories exist. If it fit into none of them reply 'general'\n",
    "   Answer with one of the five categories given above only in lower cases.\n",
    "   Answer:\"\"\"\n",
    "   \n",
    "   # API call for query classification\n",
    "   try:\n",
    "       response = llm_client.chat.completions.create(\n",
    "           model = \"gpt-4\",\n",
    "           messages=[{\"role\": \"system\", \"content\": \"You are a financial analyst specializing in SEC filing analysis.\"},\n",
    "                     {\"role\":\"user\", \"content\":query_type_prompt}\n",
    "                     ],\n",
    "           max_tokens=10,\n",
    "       )\n",
    "       query_type = response.choices[0].message.content\n",
    "   except Exception as e:\n",
    "       print(\"API call failed for query type\")\n",
    "       raise(e)                \n",
    "\n",
    "   # default to 'general' if invalid\n",
    "   if query_type not in [\"financial\", \"risk\", \"operation\", \"general\"]:\n",
    "       query_type = \"general\"\n",
    "\n",
    "   # Response Generation\n",
    "   prompt = build_prompt(question, context, query_type)\n",
    "\n",
    "   # API call for final response generation\n",
    "   try:\n",
    "       response = llm_client.chat.completions.create(\n",
    "           model=\"gpt-4\",\n",
    "           messages=[\n",
    "               {\"role\": \"system\", \"content\": \"You are a financial analyst specializing in SEC filing analysis.\"},\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ],\n",
    "           temperature=0.1,\n",
    "           max_tokens=250,\n",
    "       )\n",
    "       answer = response.choices[0].message.content\n",
    "   except Exception as e:\n",
    "       print(\"API call failed\")\n",
    "       raise(e)\n",
    "\n",
    "   # default to 'not found'\n",
    "   if answer:\n",
    "       if answer.lower() == \"not found\":\n",
    "           answer = 'not found'\n",
    "       responses.append(answer)\n",
    "   else:\n",
    "       responses.append('not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "654d89b1-2691-476b-8d70-e0355189ffd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$12,887,000',\n",
       " '$284.45 billion',\n",
       " \"The FDIC's standard maximum deposit insurance amount in 2020 was $250,000.\",\n",
       " '$35.3 million',\n",
       " \"The general risks that the company was subjected to in 2020 include:\\n\\n1. Economic and external risks due to the COVID-19 pandemic. This includes disruptions to the company, its customers, employees, and third-party service providers. The impacts of the pandemic could significantly affect the company's business, financial condition, results of operations, and prospects. Specific risks related to the pandemic include increased allowance for loan losses, declines in collateral value, impaired ability of borrowers and loan guarantors to honor commitments, reduced demand due to economic downturn, employee illness, reduced operating effectiveness due to remote work, business interruptions, unavailability of key personnel, effects on key employees, branch closures, declines in demand for loans and banking services, increased unemployment, reduced consumer spending, volatility in financial markets, and volatile performance of the company's investment securities portfolio.\\n\\n2. Changes in tax rates could unfavorably affect the company's future effective tax rates and tax liabilities. This could be due to increases in applicable tax rates, changes in federal or state tax laws, regulations and agency interpretations, changes in the valuation of deferred tax assets and liabilities, or outcomes of any examinations of the company's income tax returns by the IRS or state tax returns by the Vermont Department of Taxes.\\n\\n\",\n",
       " 'not found',\n",
       " 'The regulatory framework applicable to bank holding companies and banks includes general economic conditions, management policies, changes in federal and state laws and regulations, and actions of various regulatory authorities. The Company’s earnings are affected by these elements. Banking is a highly regulated business and proposals to change the laws and regulations to which the Company and the Bank are subject are frequently introduced at both the federal and state levels. The impact of such changes on the Company and the Bank is unpredictable.\\n\\nThe framework also includes laws designed to protect consumers of banking products and services. These laws limit the manner in which the Company may conduct business and obtain financing. The Company is subject to regular modification and change of federal and state laws, rules, regulations, and supervisory guidance, policies and interpretations. Non-compliance with these laws could result in enforcement and other legal actions by federal or state authorities, including criminal and civil penalties, the loss of FDIC insurance, revocation of a banking charter, other sanctions by regulatory agencies, civil money penalties, litigation by private parties, and/or reputational damage.\\n\\nAs a registered bank holding company, the Company is subject to ongoing regulation, supervision and examination by the Board of Governors of the Federal Reserve System (FRB), under the Bank Holding Company Act']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ba6ee-ee42-4acd-b488-67d7287f1047",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf88f2ad-0799-4b1f-976f-4b2dc0c76d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = [\n",
    "    {\n",
    "        \"query\": \"What is the outstanding amount of Subordinated Debentures in 2020?\",\n",
    "        \"expected_value\": \"$12,887,000\",\n",
    "        \"year\": \"2020\",\n",
    "        \"chunk_id\": \"6bb74a17-d3dc-4a22-91c8-a37afe5ac18e\",\n",
    "        \"section\": \"item_8\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How much money was allocated under the HHSB Act in 2020 ?\",\n",
    "        \"expected_value\": \"$284.45 billion\",\n",
    "        \"year\": \"2020\",\n",
    "        \"chunk_id\": \"d4650e17-66c5-44f7-90a1-abdd5287b7cc\",\n",
    "        \"section\": \"section_1\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the FDIC's standard maximum deposit insurance amount in 2020 ?\",\n",
    "        \"expected_value\": \"$250,000\",\n",
    "        \"year\": \"2020\",\n",
    "        \"chunk_id\": \"13b7893f-f441-4fba-a6b1-54ee5c9e3ca0\",\n",
    "        \"section\": \"section_1\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What amount of wholesale deposit was purchased in 2018 ?\",\n",
    "        \"expected_value\": \"$35.3 million\",\n",
    "        \"year\": \"2018\",\n",
    "        \"chunk_id\": \"d04471ec-a841-49a9-b656-959f2866e6bd\",\n",
    "        \"section\": \"section_1\"\n",
    "     },\n",
    "     {\n",
    "        \"query\": \"In the year 2020, what were the general risk that the company was subjected to ?\",\n",
    "        \"expected_value\": \"\"\"In 2020, the company was subject to several general risks stemming from competitive pressures, technological changes, and evolving consumer behavior in the financial services industry. One major risk was the shift in how financial services were delivered. The increasing use of online and mobile banking reduced reliance on traditional branch facilities. This trend posed a threat to the company's branch-based service model, requiring continuous evaluation of its physical infrastructure. While closing underperforming branches could improve efficiency, it also carried the risk of incurring restructuring charges and damaging customer relationships.\n",
    "Additionally, the company faced substantial competition from a wide range of financial and nonfinancial entities. These included local community banks, large national banks, credit unions with tax advantages, and non-bank financial service providers. Many of these competitors, especially larger institutions, had superior capital resources, more advanced technology, and stronger marketing capabilities. This gave them a competitive edge in attracting customers and offering more flexible or cost-effective financial products and services.\n",
    "Technological advancements also introduced new competitive threats. Financial transactions could increasingly be completed electronically without the need for a bank’s physical presence or even bank involvement at all. Consumers now had the option to transfer funds and pay bills online or by phone, using fintech services that often operated with lower costs and lighter regulatory burdens. This trend placed pressure on the company’s fee income, deposit levels, and income derived from those deposits.\n",
    "Furthermore, the emergence of out-of-market competitors offering digital-first solutions created new challenges in customer retention and acquisition. Collectively, these risks threatened the company’s market share, profitability, and long-term viability if it failed to adapt to the rapidly changing financial services landscape.\n",
    "\"\"\",\n",
    "        \"year\": \"2018\",\n",
    "        \"chunk_id\": \"36665ebd-9caa-40e1-af21-c258dc416f55\",\n",
    "        \"section\": \"section_1A\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How much money was allocated under the CARES Act in 2018 ?\",\n",
    "        \"expected_value\": \"not found\",\n",
    "        \"year\": \"2018\",\n",
    "        \"chunk_id\": None,\n",
    "        \"section\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"As of the year 2019, describes elements of an extensive regulatory framework which are applicable to bank holding companies and banks ?\",\n",
    "        \"expected_value\": \"\"\"\n",
    "Based on the 2019 SEC 10-K filing, the extensive regulatory framework for bank holding companies and banks is primarily designed to protect depositors and the FDIC Deposit Insurance Fund rather than shareholders or creditors. The framework is dominated by the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010, which comprehensively restructured financial services regulation.\n",
    "Key elements include the establishment of the Consumer Financial Protection Bureau (CFPB) with centralized authority over federal consumer financial laws, though smaller banks like the Company are enforced by agencies such as the OCC rather than the CFPB directly. The Act applies uniform leverage and risk-based capital requirements to bank holding companies on a consolidated basis, prohibiting the use of additional trust preferred securities as Tier 1 capital while grandfathering existing ones.\n",
    "Additional provisions mandate reasonable and proportional debit card interchange fees for large institutions, eliminate exclusivity arrangements between issuers and networks, and require public companies to hold shareholder votes on executive compensation matters, including \"say on executive pay\" and \"say on frequency\" votes.\n",
    "Banking operates as a highly regulated business where federal and state law changes are frequent and unpredictable. While many Dodd-Frank provisions target systemically significant large institutions, they indirectly affect smaller banking organizations through competitive pressures and regulatory standards, creating an environment where company earnings are significantly influenced by economic conditions, management policies, and regulatory authority actions.\n",
    "        \"\"\",\n",
    "        \"year\": \"2019\",\n",
    "        \"chunk_id\": \"66bb2611-a118-4d4e-ac68-009d8b2b8644\",\n",
    "        \"section\": \"section_1\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "632eaf60-1a57-4dc3-9816-19b5101d3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "correct_answers = 0\n",
    "correct_chunks = 0\n",
    "top1_chunks = 0\n",
    "bert_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54fd6d44-1b37-4045-a7c6-f89b176c7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_f1(reference, generated):\n",
    "   _, _, F1 = bert_score.score([generated], [reference], lang='en')\n",
    "   return F1.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c236f520-df0b-4d25-a221-d662b8dee480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is the outstanding amount of Subordinated Debentures in 2020?\n",
      "Expected: $12,887,000\n",
      "Generated: $12,887,000\n",
      "Expected Chunk: 6bb74a17-d3dc-4a22-91c8-a37afe5ac18e\n",
      "Retrieved Chunks: ['972a00bc-b917-45af-8690-ee685107f9e9', '6a89ecda-bb77-469f-91ec-132a43ca7081', 'b8c9e312-7209-4f97-80b8-083c7d481879']\n",
      "Retrieval Scores: ['0.463', '0.441', '0.373']\n",
      "Answer Correct: True\n",
      "\n",
      "Query: How much money was allocated under the HHSB Act in 2020 ?\n",
      "Expected: $284.45 billion\n",
      "Generated: $284.45 billion\n",
      "Expected Chunk: d4650e17-66c5-44f7-90a1-abdd5287b7cc\n",
      "Retrieved Chunks: ['41857213-f237-424b-a5e2-4b91f493e4eb', 'a990e7c6-37d0-4b5a-b487-5c7240d66020', '1e6d5bc3-f0cc-4189-a35c-85c4a379a226']\n",
      "Retrieval Scores: ['0.478', '0.454', '0.391']\n",
      "Answer Correct: True\n",
      "\n",
      "Query: What is the FDIC's standard maximum deposit insurance amount in 2020 ?\n",
      "Expected: $250,000\n",
      "Generated: The FDIC's standard maximum deposit insurance amount in 2020 was $250,000.\n",
      "Expected Chunk: 13b7893f-f441-4fba-a6b1-54ee5c9e3ca0\n",
      "Retrieved Chunks: ['fae816ad-43e6-46d8-bb6f-da718479459e', '1cdda0bb-88e4-44a6-af59-1e695e663386', '09e2e24c-2bdc-481e-a6e8-548ee1aaccd1']\n",
      "Retrieval Scores: ['0.686', '0.507', '0.488']\n",
      "Answer Correct: False\n",
      "\n",
      "Query: What amount of wholesale deposit was purchased in 2018 ?\n",
      "Expected: $35.3 million\n",
      "Generated: $35.3 million\n",
      "Expected Chunk: d04471ec-a841-49a9-b656-959f2866e6bd\n",
      "Retrieved Chunks: ['2315d1e1-2b7c-497b-adce-92413ad902f2', 'a6cd98a8-9662-48c9-a7f8-bc17dc69a5b5', 'f530720f-c186-4d2d-be5e-b904812d55c1']\n",
      "Retrieval Scores: ['0.538', '0.518', '0.494']\n",
      "Answer Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: In the year 2020, what were the general risk that the company was subjected to ?\n",
      "Expected: In 2020, the company was subject to several general risks stemming from competitive pressures, technological changes, and evolving consumer behavior in the financial services industry. One major risk was the shift in how financial services were delivered. The increasing use of online and mobile banking reduced reliance on traditional branch facilities. This trend posed a threat to the company's branch-based service model, requiring continuous evaluation of its physical infrastructure. While closing underperforming branches could improve efficiency, it also carried the risk of incurring restructuring charges and damaging customer relationships.\n",
      "Additionally, the company faced substantial competition from a wide range of financial and nonfinancial entities. These included local community banks, large national banks, credit unions with tax advantages, and non-bank financial service providers. Many of these competitors, especially larger institutions, had superior capital resources, more advanced technology, and stronger marketing capabilities. This gave them a competitive edge in attracting customers and offering more flexible or cost-effective financial products and services.\n",
      "Technological advancements also introduced new competitive threats. Financial transactions could increasingly be completed electronically without the need for a bank’s physical presence or even bank involvement at all. Consumers now had the option to transfer funds and pay bills online or by phone, using fintech services that often operated with lower costs and lighter regulatory burdens. This trend placed pressure on the company’s fee income, deposit levels, and income derived from those deposits.\n",
      "Furthermore, the emergence of out-of-market competitors offering digital-first solutions created new challenges in customer retention and acquisition. Collectively, these risks threatened the company’s market share, profitability, and long-term viability if it failed to adapt to the rapidly changing financial services landscape.\n",
      "\n",
      "Generated: The general risks that the company was subjected to in 2020 include:\n",
      "\n",
      "1. Economic and external risks due to the COVID-19 pandemic. This includes disruptions to the company, its customers, employees, and third-party service providers. The impacts of the pandemic could significantly affect the company's business, financial condition, results of operations, and prospects. Specific risks related to the pandemic include increased allowance for loan losses, declines in collateral value, impaired ability of borrowers and loan guarantors to honor commitments, reduced demand due to economic downturn, employee illness, reduced operating effectiveness due to remote work, business interruptions, unavailability of key personnel, effects on key employees, branch closures, declines in demand for loans and banking services, increased unemployment, reduced consumer spending, volatility in financial markets, and volatile performance of the company's investment securities portfolio.\n",
      "\n",
      "2. Changes in tax rates could unfavorably affect the company's future effective tax rates and tax liabilities. This could be due to increases in applicable tax rates, changes in federal or state tax laws, regulations and agency interpretations, changes in the valuation of deferred tax assets and liabilities, or outcomes of any examinations of the company's income tax returns by the IRS or state tax returns by the Vermont Department of Taxes.\n",
      "\n",
      "\n",
      "Expected Chunk: 36665ebd-9caa-40e1-af21-c258dc416f55\n",
      "Retrieved Chunks: ['fbdc1599-ec14-40c8-859f-c7c87774c312', 'a7c00aea-672d-4901-bba1-bec6da5ad2a5', '68369e36-95ab-43f0-96a5-3f2ec81a182b']\n",
      "Retrieval Scores: ['0.747', '0.609', '0.603']\n",
      "BERT F1: 0.831\n",
      "Answer Correct: True\n",
      "\n",
      "Query: How much money was allocated under the CARES Act in 2018 ?\n",
      "Expected: not found\n",
      "Generated: not found\n",
      "Expected Chunk: None\n",
      "Retrieved Chunks: ['e22424f8-8cf9-437d-a45c-a5d5a9be26e0', '356d4cfa-c63a-4357-b044-b3b1bbacaaa1', '4e208c61-8e72-472c-8909-22b17c96ed2f']\n",
      "Retrieval Scores: ['0.349', '0.328', '0.314']\n",
      "Answer Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: As of the year 2019, describe the elements of an extensive regulatory framework which are applicable to bank holding companies and banks ?\n",
      "Expected: \n",
      "Based on the 2019 SEC 10-K filing, the extensive regulatory framework for bank holding companies and banks is primarily designed to protect depositors and the FDIC Deposit Insurance Fund rather than shareholders or creditors. The framework is dominated by the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010, which comprehensively restructured financial services regulation.\n",
      "Key elements include the establishment of the Consumer Financial Protection Bureau (CFPB) with centralized authority over federal consumer financial laws, though smaller banks like the Company are enforced by agencies such as the OCC rather than the CFPB directly. The Act applies uniform leverage and risk-based capital requirements to bank holding companies on a consolidated basis, prohibiting the use of additional trust preferred securities as Tier 1 capital while grandfathering existing ones.\n",
      "Additional provisions mandate reasonable and proportional debit card interchange fees for large institutions, eliminate exclusivity arrangements between issuers and networks, and require public companies to hold shareholder votes on executive compensation matters, including \"say on executive pay\" and \"say on frequency\" votes.\n",
      "Banking operates as a highly regulated business where federal and state law changes are frequent and unpredictable. While many Dodd-Frank provisions target systemically significant large institutions, they indirectly affect smaller banking organizations through competitive pressures and regulatory standards, creating an environment where company earnings are significantly influenced by economic conditions, management policies, and regulatory authority actions.\n",
      "        \n",
      "Generated: The regulatory framework applicable to bank holding companies and banks includes general economic conditions, management policies, changes in federal and state laws and regulations, and actions of various regulatory authorities. The Company’s earnings are affected by these elements. Banking is a highly regulated business and proposals to change the laws and regulations to which the Company and the Bank are subject are frequently introduced at both the federal and state levels. The impact of such changes on the Company and the Bank is unpredictable.\n",
      "\n",
      "The framework also includes laws designed to protect consumers of banking products and services. These laws limit the manner in which the Company may conduct business and obtain financing. The Company is subject to regular modification and change of federal and state laws, rules, regulations, and supervisory guidance, policies and interpretations. Non-compliance with these laws could result in enforcement and other legal actions by federal or state authorities, including criminal and civil penalties, the loss of FDIC insurance, revocation of a banking charter, other sanctions by regulatory agencies, civil money penalties, litigation by private parties, and/or reputational damage.\n",
      "\n",
      "As a registered bank holding company, the Company is subject to ongoing regulation, supervision and examination by the Board of Governors of the Federal Reserve System (FRB), under the Bank Holding Company Act\n",
      "Expected Chunk: 66bb2611-a118-4d4e-ac68-009d8b2b8644\n",
      "Retrieved Chunks: ['81d9f696-70e3-4f5d-a35d-bffa640924c4', 'eb921e71-ee58-426b-86a3-cfd8758f2069', '1ebdc5e8-dfef-4b9a-8add-d8787b24ebe7']\n",
      "Retrieval Scores: ['0.759', '0.673', '0.655']\n",
      "BERT F1: 0.842\n",
      "Answer Correct: True\n"
     ]
    }
   ],
   "source": [
    "for i, (query, response) in enumerate(zip(query_list, responses)):\n",
    "   expected = validation[i]['expected_value']\n",
    "   expected_chunk = validation[i]['chunk_id']\n",
    "   \n",
    "   chunk_ids = [row[\"chunk_id\"] for row in query[\"context\"]]\n",
    "   scores = [row[\"score\"] for row in query[\"context\"]]\n",
    "   \n",
    "   # Evaluating answer for keyword match vs semantic match\n",
    "   use_bert = len(expected) > 15 and '$' not in expected\n",
    "   if use_bert:\n",
    "       bert_f1_response = bert_f1(expected, response)\n",
    "       bert_scores.append(bert_f1_response)\n",
    "       answer_correct = bert_f1_response > 0.8\n",
    "   else:\n",
    "       bert_f1_response = None\n",
    "       answer_correct = expected.strip() == response.strip()\n",
    "   \n",
    "   # Evaluating chunks\n",
    "   # Only works if Validation set used same chunked dataset from /Knowledge\n",
    "   chunk_correct = expected_chunk in chunk_ids if expected_chunk else True\n",
    "   top1_correct = chunk_ids[0] == expected_chunk if chunk_ids and expected_chunk else False\n",
    "   \n",
    "   # Count metrics\n",
    "   correct_answers += answer_correct\n",
    "   correct_chunks += chunk_correct\n",
    "   top1_chunks += top1_correct\n",
    "   \n",
    "   # Store results\n",
    "   results.append({\n",
    "       'Query': query['query'],\n",
    "       'Expected_Answer': expected,\n",
    "       'Generated_Answer': response,\n",
    "       'Expected_Chunk_ID': expected_chunk,\n",
    "       'Retrieved_Chunk_IDs': ', '.join(chunk_ids),\n",
    "       'Answer_Correct': answer_correct,\n",
    "       'Chunk_Retrieved': chunk_correct,\n",
    "       'Top1_Chunk_Match': top1_correct,\n",
    "       'BERT_F1_Score': bert_f1,\n",
    "       'Avg_Retrieval_Score': f\"{sum(scores)/len(scores):.3f}\" if scores else \"0.000\"\n",
    "   })\n",
    "   \n",
    "   # Print details\n",
    "   print(f\"\\nQuery: {query['query']}\")\n",
    "   print(f\"Expected: {expected}\")\n",
    "   print(f\"Generated: {response}\")\n",
    "   print(f\"Expected Chunk: {expected_chunk}\")\n",
    "   print(f\"Retrieved Chunks: {chunk_ids}\")\n",
    "   print(f\"Retrieval Scores: {[f'{s:.3f}' for s in scores]}\")\n",
    "   if bert_f1_response:\n",
    "       print(f\"BERT F1: {bert_f1_response:.3f}\")\n",
    "   print(f\"Answer Correct: {answer_correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d87a1cb-4e81-4b95-b406-218bf40d3336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION SUMMARY\n",
      "\n",
      "==================================================\n",
      "Answer_Accuracy: 85.7%\n",
      "Chunk_Recall: 14.3%\n",
      "Top1_Chunk_Accuracy: 0.0%\n",
      "Avg_BERT_F1: 0.836\n",
      "BERT_Pass_Rate: 100.0%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "total = len(queries)\n",
    "metrics = {\n",
    "   'Answer_Accuracy': f\"{correct_answers/total:.1%}\",\n",
    "   'Chunk_Recall': f\"{correct_chunks/total:.1%}\",\n",
    "   'Top1_Chunk_Accuracy': f\"{top1_chunks/total:.1%}\",\n",
    "   'Avg_BERT_F1': f\"{sum(bert_scores)/len(bert_scores):.3f}\" if bert_scores else \"N/A\",\n",
    "   'BERT_Pass_Rate': f\"{sum(1 for s in bert_scores if s > 0.8)/len(bert_scores):.1%}\" if bert_scores else \"N/A\"\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"EVALUATION SUMMARY\\n\")\n",
    "print(f\"{'='*50}\")\n",
    "for key, value in metrics.items():\n",
    "   print(f\"{key}: {value}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bb7f9-2918-4655-97ef-c1dafd69a2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
